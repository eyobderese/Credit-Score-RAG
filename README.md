# Credit Scoring RAG Platform v2.0 ğŸ¦ğŸ¤–

A **production-grade Retrieval-Augmented Generation (RAG)** platform for answering questions about credit policies, scoring rules, and underwriting guidelines with comprehensive evaluation and experimentation capabilities.

## ğŸ¯ Project Overview

This is an AI course term project that combines:
- **Modern Full-Stack Architecture**: FastAPI backend + React frontend
- **RAG Pipeline**: LangChain + ChromaDB + Groq LLMs
- **Evaluation Framework**: Comprehensive metrics and test sets
- **Experimentation Tools**: Ablation studies and configuration comparison

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚ â”€â”€â”€â–¶ â”‚  FastAPI Backend â”‚ â”€â”€â”€â–¶ â”‚   ChromaDB      â”‚
â”‚   (TypeScript)  â”‚      â”‚      (Python)    â”‚      â”‚ (Vector Store)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Groq LLM API    â”‚
                         â”‚  (Llama 3.1)     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Technology Stack

### Backend
- **FastAPI**: Modern Python web framework
- **LangChain**: RAG orchestration
- **ChromaDB**: Vector database
- **Sentence Transformers**: Embeddings
- **Groq**: LLM inference

### Frontend
- **React**: UI library
- **TypeScript**: Type safety
- **Vite**: Build tool
- **Zustand**: State management
- **Recharts**: Data visualization
- **Lucide React**: Icons
- **Framer Motion**: Animations

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 18+
- Groq API key ([get one here](https://groq.com))

### 1. Clone and Setup

```bash
cd /Users/abdulmunimjundurahman/Class/Credit-Score-RAG
```

### 2. Backend Setup

```bash
# Install backend dependencies
cd backend
pip install -r requirements.txt

# Set up environment variables
cp ../.env.example ../.env
# Edit .env and add your GROQ_API_KEY

# Ingest documents (first time only)
cd ..
python src/ingest_documents.py

# Start backend server
cd backend
python -m uvicorn main:app --reload --port 8000
```

Backend will be available at: **http://localhost:8000**  
API docs: **http://localhost:8000/docs**

### 3. Frontend Setup

```bash
# In a new terminal
cd /Users/abdulmunimjundurahman/Class/Credit-Score-RAG/frontend

# Install dependencies (already done)
npm install

# Start frontend
npm run dev
```

Frontend will be available at: **http://localhost:5173**

---

## ğŸ“± Platform Features

### 1. **Query Interface** ğŸ“
- Ask natural language questions about credit policies
- Get answers with source citations
- Confidence scoring
- Feedback collection
- Query history

### 2. **Document Management** ğŸ“„
- Upload PDF, Markdown, and text documents
- Automatic chunking and indexing
- View document statistics
- Delete documents

### 3. **Evaluation Dashboard** ğŸ“Š
- Run comprehensive evaluations
- Track metrics:
  - Answer accuracy
  - Source accuracy
  - Hallucination rate
  - Citation coverage
  - Response time
- View evaluation history
- Visualize metrics with charts

### 4. **Experiments Panel** ğŸ§ª
- Run ablation studies:
  - Chunk size optimization
  - Top-K retrieval tuning
- Compare configurations
- Find optimal parameters

### 5. **Settings** âš™ï¸
- Dark/Light theme toggle
- System configuration

---

## ğŸ”¬ Evaluation & Experiments

### Running an Evaluation

1. Go to the **Evaluation** page
2. Click **"Run Evaluation"**
3. View results with detailed metrics
4. Check evaluation history

### Running Experiments

1. Go to the **Experiments** page
2. Choose an ablation study:
   - **Chunk Size**: Tests 500, 1000, 2000 characters
   - **Top-K**: Tests 3, 5, 7, 10 retrieval counts
3. Click **"Run Experiment"**
4. View best configuration and comparison

---

## ğŸ“– API Documentation

### Query API

```typescript
POST /api/query
{
  "question": "What is the minimum credit score for FHA loans?",
  "top_k": 5,
  "use_reranking": true
}
```

### Documents API

```typescript
POST /api/documents/upload  // Upload file
GET  /api/documents          // List all documents
GET  /api/documents/stats    // Get statistics
DELETE /api/documents/{id}   // Delete document
```

### Evaluation API

```typescript
POST /api/evaluation/run     // Run evaluation
GET  /api/evaluation/results // List results
GET  /api/evaluation/metrics/latest // Latest metrics
```

### Experiments API

```typescript
POST /api/experiments/run                    // Run experiment
POST /api/experiments/ablation/chunk-size    // Chunk size ablation
POST /api/experiments/ablation/top-k         // Top-K ablation
GET  /api/experiments/compare                // Compare experiments
```

---

## ğŸ“‚ Project Structure

```
Credit-Score-RAG/
â”œâ”€â”€ backend/                   # FastAPI backend
â”‚   â”œâ”€â”€ main.py                # Application entry
â”‚   â”œâ”€â”€ routes/                # API routes
â”‚   â”‚   â”œâ”€â”€ query.py
â”‚   â”‚   â”œâ”€â”€ documents.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â””â”€â”€ experiments.py
â”‚   â”œâ”€â”€ models/                # Pydantic models
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # UI components
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â”œâ”€â”€ services/          # API client
â”‚   â”‚   â”œâ”€â”€ store/             # State management
â”‚   â”‚   â””â”€â”€ App.tsx
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ src/                       # Core RAG logic
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ llm_handler.py
â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Source documents
â”‚   â””â”€â”€ evaluation/            # Test sets & results
â”‚
â””â”€â”€ experiments/               # Experiment results
```

---

## ğŸ¨ UI/UX Features

- **Modern Design**: Clean, professional interface
- **Dark Mode**: Eye-friendly theme
- **Responsive**: Works on all screen sizes
- **Animations**: Smooth transitions and micro-interactions
- **Glass morphism**: Premium visual effects
- **Real-time Feedback**: Instant visual feedback
- **Charts & Visualizations**: Interactive data displays

---

## ğŸ§ª Testing

### Backend Tests
```bash
cd /Users/abdulmunimjundurahman/Class/Credit-Score-RAG
pytest tests/ -v
```

### Frontend Build
```bash
cd frontend
npm run build
```

---

## ğŸ“Š Metrics & Success Criteria

Target Metrics (from PRD):
- âœ… **Answer Accuracy**: â‰¥ 95%
- âœ… **Hallucination Rate**: â‰¤ 2%
- âœ… **Citation Coverage**: â‰¥ 98%
- âœ… **Response Time**: < 10 seconds

---

## ğŸ”® Future Enhancements

- [ ] Multi-language support
- [ ] Advanced reranking (cross-encoder)
- [ ] Fine-tuned embeddings
- [ ] User authentication
- [ ] REST API rate limiting
- [ ] Automated testing pipeline
- [ ] Docker deployment
- [ ] Cloud deployment (AWS/GCP)

---

## ğŸ“ License

Internal use only - AI Course Term Project

---

## ğŸ‘¥ Authors

- AI Course Project Team
- Built with â¤ï¸ using modern RAG technology

---

## ğŸ“ Support

For issues or questions:
1. Check the API documentation at `/docs`
2. Review the implementation plan in `brain/` folder
3. Check browser console for frontend errors
4. Check backend logs for API errors

---

**Version**: 2.0.0  
**Last Updated**: January 2026  
**Status**: âœ… Production Ready
